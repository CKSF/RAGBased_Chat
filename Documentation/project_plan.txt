项目名称：思政领域RAG大模型应用开发
日期：2025-12-12
主题：技术实现拆解、实施阶段规划及资源需求说明

尊敬的项目组：

为了确保项目在既定截止日期（DDL）前高质量交付，技术团队对收到的需求（共四点）进行了深度的技术拆解和可行性评估。
我们充分理解该项目的创新性和重要性，为了弥合用户对前沿技术（CS/AI/LLM）的认知差异，特此制定本实施规划，明确技术实施路径、依赖条件及风险边界。

一、 功能技术拆解与所需支持

我们需要向您解释每项功能背后的技术实现逻辑。为了保证系统的专业性，我们在底层架构上采用了目前行业最前沿的方案。

1. 答疑功能（核心优先）
   - 技术逻辑（专业视角）：
     本功能基于 RAG (Retrieval-Augmented Generation，检索增强生成) 架构开发。首先需要构建数据管道，对非结构化文档进行清洗、语义分块和 向量化嵌入，并存入高维向量数据库。
     简单来说，这是一场“开卷考试”。AI 系统就像一个图书管理员，从我们建立的知识库中精准翻到具体的页码和段落，再组织语言回答问题。
   - 甲方需提供材料：
     目前仅有1个100页的PDF作为 Demo 是不够的。若要实现对100个文档的精准问答，我们需要您提供这100个文档的可编辑电子版（Word/PDF/TXT），且必须是最终定稿版本。
   - 预期交付效果：
     实现基于现有文档库的准确问答，回答内容可溯源，严格遵守思政内容的严肃性。

2. 教案生成（核心优先）
   - 技术逻辑（专业视角）：
     该模块涉及结构化文本生成技术。我们将采用思维链提示策略，结合少样本学习，将教学原理注入模型。通过定义严格的输出约束，确保模型生成的非结构化内容能够自动映射为标准的教案格式（教学目标、重难点、过程设计等），并支持后续的文档渲染（可以定制PDF格式， 后期可以提供在线 PDF 教案的预览编辑， 模版选择等功能）。
     简单来说，这是一个复杂的“填空题”。AI 学习了优秀教案范本后，掌握了“好教案”的骨架。老师只需要输入课程主题，AI 就能生成一份结构完整的教案初稿。
   - 甲方需提供材料：
     3-5份“优质教案范本”。AI 需要数据进行对齐，我们需要知道什么是贵方认可的“标准格式”和“行文风格”。
   - 预期交付效果：
     按照固定模板生成结构完整的教案文本，支持导出。

3. 个性化学习辅导（需二期建设）
   - 技术逻辑（专业视角）：
     此功能属于高阶推荐系统与 AI 的结合。技术上需要构建用户画像系统，采集用户的显性反馈与隐性行为日志，尝试构建领域知识图谱。基于协同过滤或基于内容的推荐算法，动态生成学习路径。这在产品和技术角度都需要大量的数据冷启动积累。
     简单来说，这相当于请一个“私教”。但前提是私教必须认识这个学生很长时间，了解他的强项和弱项（数据积累）。目前系统是全新的，没有“学生历史数据”，AI 就无法进行针对性分析。
   - 现状与难点：
     知识图谱的构建和用户行为分析是浩大的工程，通常不属于 MVP（最小可行性产品）阶段的开发范围。
   - 建议：
     本阶段仅搭建基础数据采集框架，个性化算法建议放在系统上线、积累足够用户数据（约3个月）后进行迭代。

4. 面试答疑辅导（需二期建设）
   - 技术逻辑（专业视角）：
     涉及复杂的多轮对话状态追踪和角色扮演机制。系统需要维护长窗口的会话上下文，并引入自动评估模型，将用户的自然语言回复与标准采分点进行语义比对，计算相似度得分。
     简单来说，这是“模拟面试”。AI 既要扮演考官追问，又要扮演评委打分。这需要非常详细的题库和评分标准作为支撑。
   - 甲方需提供材料：
     结构化的面试题库、标准答案、详细评分细则。
   - 建议：
     鉴于目前数据缺失，本功能建议作为进阶模块，在核心功能稳定后开发。

二、 项目分期与预期管理

鉴于最初约定的开发周期（DDL）是基于核心需求（1和2）制定的，且需求3和4涉及极高的数据清洗成本和算法研发复杂度，我们会采用敏捷开发模式，将项目分为两个里程碑：

【第一阶段：核心交付期（当前DDL前）】
- 目标：确保系统“能用”、“鲁棒性强”。
- 交付内容：
    1. 包含完整 UI/UX 交互的 Web 系统。
    2. 核心答疑 Agent 上线：支持 RAG 文档检索，回答准确率达标。
    3. 教案生成 Agent 上线：支持标准模板输出。
    4. 基础 CMS (内容管理系统)：用于上传和管理那100个文档。

【第二阶段：智能化升级期（DDL后，需额外工时）】
- 目标：让系统“聪明”、“懂用户”。
- 交付内容：
    1. 实施“个性化学习辅导”：基于前期积累的数据训练推荐算法。
    2. 实施“面试辅导”：增加多轮对话逻辑和自动打分系统。
- 原因说明：没有第一阶段的数据“沉淀和积累”，第二阶段的功能无法实现。

三、 数据量级扩容的风险提示 (Scalability Risks)

目前我们在开发环境仅使用了一个 100页的 PDF 进行 POC (概念验证)。最终上线环境需要支持 100个 文档（可能是数万页）：
1. 信噪比问题：文档数量增加导致检索干扰项呈指数级上升，可能导致检索准确率（Recall/Precision）波动。
2. 数据清洗：这 100 个文档必须经过严格的 OCR (如有扫描件) 和格式清洗。如果源数据格式混乱（如乱码、排版错乱），将直接导致“Garbage In, Garbage Out”（垃圾进，垃圾出）。
3. 确认事项：100个文档的数据整理和清洗工作量巨大，需要甲方业务专家配合确认内容准确性。

四、 开发与运营成本清单 (Cost Structure)

除了软件开发费用外，生成式 AI 系统的运行依赖于以 Token 为单位计费的云端算力，这属于持续性运营成本（OPEX）：
1. 大模型推理费：每次提问和生成教案都会调用 API（预计使用 GPT-4o 或同级别高性能模型），按字符量计费。
2. 向量存储费：100个文档切片后的高维向量数据需要存储在专用的 Cloud Vector DB 中。
3. 云基础设施：包含应用服务器、带宽及数据库租赁费用。

我们建议尽快确认以上技术路线和分期方案，以便团队能聚焦精力，在 DDL 前完成 RAG 引擎和 Prompt 模板的精细化调优，确保核心功能的完美呈现。

五、 关键边界与责任核定（重要总结）

基于我们此前的沟通与现状，特此对项目边界进行最终核定，以免后续产生分歧：

1. 开发范围界定 (Scope Definition)
   - 我们的初始约定仅包含 **纯后端逻辑开发**（RAG架构搭建、向量数据库构建、LLM对话逻辑实现）。
   - **不包含** 生产环境的云端部署运维 (DevOps)、域名备案、服务器安全防护等工作。若需我方协助生产环境部署，属于额外增值服务。
   - 基础设施归属：所有云资源（云服务器 ECS、**火山引擎 (Volcengine)** API Key、向量数据库实例）需由 **甲方注册并提供账号**，我方只负责代码对接与调试。

2. 数据与效果的预期管理 (Expectation on Data)
   - 现状：目前仅依据 **1个 PDF** 进行 Demo 开发与验证。
   - 风险：实际应用中若拓展至 100 个文档，且文档格式不统一（如混杂扫描件、图片、手写体），将导致检索效果下降。
   - 声明：我们对交付质量的承诺基于 **“现有数据质量”**。若后续提供的 100 个文档需要大量且复杂的清洗（如人工OCR校对、格式重排），这部分 **数据清洗 (Data Cleaning)** 工作量需额外评估，或由甲方团队配合完成。

3. 当前阻塞项 (Current Blockers)
   - 为推进第一阶段开发，请务必尽快提供：
     1. **教案生成的标准模板**（3-5份，这是训练 AI 模仿写作风格的核心依据）。
     2. **大模型 API Key**：已收到 (DeepSeek R1 via Volcengine)。