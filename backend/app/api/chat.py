import json
import traceback
from flask import Blueprint, request, jsonify, stream_with_context, Response
from backend.app.services import rag_service, llm_service

chat_bp = Blueprint('chat', __name__)

def format_sse(event_type: str, data: dict):
    """Helper to format Server-Sent Events (SSE)."""
    return f"data: {json.dumps({'type': event_type, 'data': data}, ensure_ascii=False)}\n\n"

@chat_bp.route('/send', methods=['POST'])
def send_message():
    # 1. Parse Request
    req_data = request.json
    user_message = req_data.get('message', '')
    history = req_data.get('history', [])
    # Get grade, default to 'ä¸é™' (No Filter)
    grade = req_data.get('grade', 'ä¸é™')

    # --- FILTER LOGIC (Copied from Lesson BP) ---
    rag_filters = {}
    if grade and grade != 'ä¸é™':
        if "å°å­¦" in grade:
            rag_filters = {"grade": "å°å­¦"}
        elif "åˆä¸­" in grade:
            rag_filters = {"grade": "åˆä¸­"}
        elif "é«˜ä¸­" in grade:
            rag_filters = {"grade": "é«˜ä¸­"}
        elif "å¤§å­¦" in grade or "æœ¬ç§‘" in grade:
            rag_filters = {"grade": "å¤§å­¦"}
        elif "ç¡•å£«" in grade or "ç ”ç©¶ç”Ÿ" in grade:
            rag_filters = {"grade": "ç¡•å£«"}
        elif "åšå£«" in grade:
            rag_filters = {"grade": "åšå£«"}

    def generate():
        try:
            # --- STEP 1: QUERY REWRITING ---
            # We append the grade to the query context so the rewriter knows the level
            rewrite_context_msg = f"{user_message} (Target Audience: {grade})"
            
            yield format_sse('thought', "ğŸ¤” æ­£åœ¨ç†è§£æ‚¨çš„é—®é¢˜ä¸Šä¸‹æ–‡...")
            rewritten_query = llm_service.rewrite_query(rewrite_context_msg, history)
            
            # If rewrite failed/skipped, ensure we still search for the user message
            final_query = rewritten_query if rewritten_query else user_message

            if final_query != user_message:
                yield format_sse('thought', f"ğŸ”„ ä¼˜åŒ–æŸ¥è¯¢ä¸º: â€œ{final_query}â€")

            # --- STEP 2: RAG RETRIEVAL ---
            yield format_sse('thought', f"ğŸ“š æ­£åœ¨æ£€ç´¢æ€æ”¿çŸ¥è¯†åº“ (Filter: {rag_filters})...")
            
            # Perform Query with FILTERS
            documents = rag_service.query(final_query, k=8, filters=rag_filters)
            
            # --- STEP 3: INTERMEDIATE DATA ---
            doc_count = len(documents)
            if doc_count == 0:
                yield format_sse('thought', "âš ï¸ æœªæ‰¾åˆ°ç›¸å…³èµ„æ–™ï¼Œå°†åŸºäºé€šç”¨çŸ¥è¯†å›ç­”ã€‚")
                context_text = ""
                sources = []
            else:
                sources = list(set([doc.metadata.get('source', 'Unknown') for doc in documents]))
                yield format_sse('thought', f"âœ… æ£€ç´¢å®Œæˆï¼šæ‰¾åˆ° {doc_count} ä»½ç›¸å…³æ–‡æ¡£ã€‚")
                yield format_sse('thought', f"ğŸ“„ å‚è€ƒæ¥æº: {', '.join(sources)}")
                
                context_text = ""
                for doc in documents:
                    # Display Grade in Context so LLM sees it
                    doc_grade = doc.metadata.get('grade', 'é€šç”¨')
                    context_text += f"\n---\n[Source: {doc.metadata.get('source')} | é€‚ç”¨: {doc_grade}]\n{doc.page_content}\n"

            # --- STEP 4: LLM GENERATION ---
            yield format_sse('thought', "ğŸ§  æ­£åœ¨æ•´ç†ç­”æ¡ˆ...")
            

            
            system_prompt = (
    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ€æ”¿è¯¾åŠ©æ•™å¤§æ¨¡å‹ã€‚è¯·æ ¹æ®æä¾›çš„ã€èƒŒæ™¯èµ„æ–™ã€‘(Context) å®¢è§‚ã€ä¸¥è°¨åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n"
    "åœ¨å›ç­”ä¹‹å‰ï¼Œè¯·å…ˆåˆ¤æ–­æä¾›çš„ã€èƒŒæ™¯èµ„æ–™ã€‘æ˜¯å¦èƒ½å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š\n\n"
    "**æƒ…å†µä¸€ï¼šèµ„æ–™é«˜åº¦ç›¸å…³**\n"
    "- å¿…é¡»**ä¼˜å…ˆ**å¼•ç”¨èµ„æ–™ä¸­çš„åŸæ–‡ã€è§‚ç‚¹æˆ–æ¡ˆä¾‹ã€‚\n"
    "- ä¸¥ç¦è„±ç¦»èµ„æ–™è¿›è¡Œä¸å¿…è¦çš„å‘æŒ¥ã€‚\n\n"
    "**æƒ…å†µäºŒï¼šèµ„æ–™ä¸ç›¸å…³ã€ç›¸å…³åº¦ä½ æˆ– æ— æ³•å›ç­”æ ¸å¿ƒé—®é¢˜**\n"
    "- **å¿…é¡»**åœ¨å›ç­”çš„æœ€å¼€å§‹ï¼Œ**åŠ ç²—**è¾“å‡ºä»¥ä¸‹å…è´£å£°æ˜ï¼š\n"
    "  > **ã€æ³¨ï¼šçŸ¥è¯†åº“ä¸­æœªåŒ¹é…åˆ°é«˜ç›¸å…³åº¦èµ„æ–™ï¼Œä»¥ä¸‹å†…å®¹åŸºäºé€šç”¨çŸ¥è¯†è¡¥å……ï¼Œä»…ä¾›å‚è€ƒã€‚ã€‘**\n"
    "### æ ¸å¿ƒåŸåˆ™ï¼š\n"
    "1. **ä¼˜å…ˆåŸæ–‡**ï¼šå›ç­”å¿…é¡»åŸºäº èƒŒæ™¯èµ„æ–™(Context) å†…å®¹ã€‚å¦‚æœ èƒŒæ™¯èµ„æ–™(Context) åŒ…å«ç¡®åˆ‡ç­”æ¡ˆï¼Œè¯·ç›´æ¥å¼•ç”¨ã€‚\n"
    "2. **ä¸¥ç¦ç¼–é€ **ï¼šå¦‚æœèµ„æ–™ä¸­æ²¡æœ‰ç­”æ¡ˆï¼Œå¿…é¡»è¯šå®è¯´æ˜ã€‚å¦‚æœç”¨æˆ·é—®â€œçº¢å†›é•¿å¾â€ï¼Œè€Œèµ„æ–™é‡Œå…¨æ˜¯â€œæ”¹é©å¼€æ”¾â€ï¼Œè¯·ç›´æ¥æŒ‰ã€æƒ…å†µäºŒã€‘å¤„ç†ï¼Œç»å¯¹ä¸è¦å¼ºè¡ŒæŠŠæ”¹é©å¼€æ”¾çš„å†…å®¹å¥—ç”¨åˆ°é•¿å¾ä¸Šã€‚å¦‚æœä¸ç¡®å®šï¼Œå°±è¯´ä¸çŸ¥é“ã€‚\n"
    "3. **ä¸¥ç¦æé€ ç›´æ¥å¼•ç”¨**ï¼šå¦‚æœè¦åŠ å…¥ç›´æ¥å¼•ç”¨ï¼Œå¿…é¡»ç¡®è®¤å¼•ç”¨å†…å®¹æ˜¯èƒŒæ™¯èµ„æ–™ä¸­çš„åŸæ–‡ï¼Œä¸¥ç¦å‡ºç°ä»»ä½•ä½¿ç”¨é€šç”¨çŸ¥è¯†è¡¥å……ã€è‡ªç”±å‘æŒ¥å’Œè‡ªè¡Œæé€ çš„å¼•ç”¨ã€‚ç›´æ¥å¼•ç”¨åœ¨å›ç­”ä¸­æœ€å¤šå‡ºç°ä¸‰æ¬¡ï¼Œä¸”æ ¹æ®ä½ ç¡®å®šå‘ç”Ÿè¿‡çš„å¯éªŒè¯çš„ç›´æ¥å¼•ç”¨æ’åºã€‚å¼•ç”¨å¿…é¡»å¸¦æœ‰ä¿¡æ¯æ¥æºçš„æ ‡æ³¨ï¼ˆå¦‚ï¼šæ ¹æ®ã€Š...ã€‹ï¼‰ã€‚\n"
    "4. **é£æ ¼è¦æ±‚**ï¼šä¸¥è°¨ã€å‡†ç¡®ã€ç§¯ææ­£å‘ã€‚\n"
    "5. **å¼•ç”¨è¯´æ˜**ï¼šå›ç­”ä¸­æ³¨æ˜ä¿¡æ¯çš„æ¥æºï¼ˆå¦‚ï¼šæ ¹æ®ã€Š...ã€‹ï¼‰ã€‚\n\n"
    f"6. å¹´çº§ä¸¥æ ¼é™åˆ¶ï¼šå½“å‰è®¾å®šçš„ç›®æ ‡ç”¨æˆ·å¹´çº§ä¸ºã€{grade}ã€‘ã€‚æˆ–è€…å¦‚æœç”¨æˆ·æåˆ°äº†ç›®æ ‡å¹´çº§ï¼ˆä¾‹å¦‚â€œå¤§å­¦ç”Ÿâ€ã€â€œå°å­¦ç”Ÿâ€ã€æˆ–è€…â€œå°å­¦å››å¹´çº§â€æ—¶ï¼‰"
                "   - å¦‚æœæ˜¯å°å­¦ï¼š**ä¸¥ç¦**å‡ºç°åˆä¸­/é«˜ä¸­/å¤§å­¦/ç ”ç©¶ç”Ÿ/åšå£«çš„å¤æ‚çš„æ”¿æ²»æœ¯è¯­ã€å“²å­¦æ¦‚å¿µæˆ–è¿‡æ·±çš„ç†è®ºåˆ†æã€‚\n"
                "   - å¦‚æœæ˜¯å¤§å­¦ï¼š**ä¸¥ç¦**ä½¿ç”¨ä½å¹¼åŒ–çš„è¯­è¨€æˆ–ç®€å•çš„ç”Ÿæ´»æ¡ˆä¾‹ã€‚\n"
                "   - **ç»å¯¹ç¦æ­¢**å‘ç”Ÿâ€œå¹´çº§æ³„æ¼â€ï¼ˆå¦‚ï¼šæ˜æ˜æ˜¯äº”å¹´çº§æ•™æ¡ˆï¼Œå´å¼•ç”¨äº†å…­å¹´çº§æˆ–åˆä¸­çš„è¯¾æ ‡è¦æ±‚ï¼‰ã€‚ä½å¹´çº§æ•™æ¡ˆç¦æ­¢ä½¿ç”¨ä¸€åˆ‡æ¥æºè‡ªé«˜å¹´çº§çš„èµ„æ–™ï¼ŒåŒ…æ‹¬æ¦‚å¿µã€æ•™æ¡ˆã€æ¡ˆä¾‹ã€æ¼”ç¤ºç­‰ä¸€åˆ‡æ¨¡æ€çš„ä¿¡æ¯ã€‚\n"
    "### æ ¼å¼å¼ºåˆ¶è§„èŒƒ (Critical Output Rules)ï¼š\n"
    "ç”±äºå‰ç«¯æ˜¾ç¤ºé™åˆ¶ï¼Œ**ç³»ç»Ÿæ— æ³•æ¸²æŸ“ä»»ä½•å›¾è¡¨ä»£ç **ã€‚ä½ å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š\n"
    "1. **ç»“æ„åŒ–é™çº§å¤„ç†**ï¼š\n"
    "   - å½“ä½ æƒ³ç”»â€œæµç¨‹å›¾â€æ—¶ï¼Œ**å¿…é¡»**æ”¹å†™ä¸ºã€å¸¦åºå·çš„æ­¥éª¤åˆ—è¡¨ã€‘(1. -> 2. -> 3.)ã€‚\n"
    "   - å½“ä½ æƒ³ç”»â€œæ€ç»´å¯¼å›¾â€æˆ–â€œå±‚çº§ç»“æ„â€æ—¶ï¼Œ**å¿…é¡»**æ”¹å†™ä¸ºã€å¤šçº§ç¼©è¿›åˆ—è¡¨ã€‘(- ç¬¬ä¸€å±‚ \n  - ç¬¬äºŒå±‚)ã€‚\n"
    "   - å½“ä½ æƒ³ç”»â€œé¥¼å›¾â€æˆ–â€œè¡¨æ ¼â€æ—¶ï¼Œ**å¿…é¡»**ä½¿ç”¨æ ‡å‡†çš„ Markdown è¡¨æ ¼ (| header | ...)ã€‚\n"
    "2. **ç»å¯¹ç¦æ­¢**ï¼š\n"
    "   - ä¸¥ç¦è¾“å‡ºä»»ä½• ```mermaid, ```flowchart, ```graph, ```pie ç­‰ä»£ç å—ã€‚\n"
    "   - ä¸¥ç¦è¾“å‡º `<svg>` æ ‡ç­¾ã€‚\n"
    "   - è¾“å‡ºå†…å®¹å¿…é¡»æ˜¯ç›´æ¥å¯è¯»çš„çº¯æ–‡æœ¬ Markdownã€‚"
    f"\n\n### èƒŒæ™¯èµ„æ–™ (Context):\n{context_text}"
)

            # Stream the actual text token-by-token
            for token in llm_service.stream_response(user_message, system_prompt, history):
                yield format_sse('token', token)
            
            yield format_sse('done', {"sources": sources})

        except Exception as e:
            traceback.print_exc()
            yield format_sse('error', str(e))

    return Response(stream_with_context(generate()), mimetype='text/event-stream')