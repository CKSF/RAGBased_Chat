import json
import traceback
from flask import Blueprint, request, Response, stream_with_context
from backend.app.services import rag_service, llm_service

lesson_bp = Blueprint('lesson', __name__)

def format_sse(event_type: str, data: dict):
    """Helper to format Server-Sent Events."""
    return f"data: {json.dumps({'type': event_type, 'data': data}, ensure_ascii=False)}\n\n"

@lesson_bp.route('/generate', methods=['POST'])
def generate_lesson_plan():
    """
    Generate a lesson plan via Streaming.
    Payload: { "topic": "é«˜è´¨é‡å‘å±•", "grade": "å°å­¦" }
    """
    req_data = request.json
    topic = req_data.get('topic', '')
    grade = req_data.get('grade', 'é€šç”¨')

    # --- 1. Construct RAG Filters based on Grade ---
    # We must map the user's input grade to the specific tags used in build_db.py
    # Valid tags: "å°å­¦", "åˆä¸­", "é«˜ä¸­", "å¤§å­¦", "ç¡•å£«", "åšå£«"
    rag_filters = {}
    
    if grade and grade != 'é€šç”¨':
        # Simple substring matching ensures that "å°å­¦äº”å¹´çº§" -> filter: "å°å­¦"
        if "å°å­¦" in grade:
            rag_filters = {"grade": "å°å­¦"}
        elif "åˆä¸­" in grade:
            rag_filters = {"grade": "åˆä¸­"}
        elif "é«˜ä¸­" in grade:
            rag_filters = {"grade": "é«˜ä¸­"}
        elif "å¤§å­¦" in grade or "æœ¬ç§‘" in grade:
            rag_filters = {"grade": "å¤§å­¦"}
        elif "ç¡•å£«" in grade or "ç ”ç©¶ç”Ÿ" in grade:
            rag_filters = {"grade": "ç¡•å£«"}
        elif "åšå£«" in grade:
            rag_filters = {"grade": "åšå£«"}
        # Note: If no match (e.g. "æˆäººæ•™è‚²"), filters remains empty, relying on semantic search only.

    def generate():
        try:
            # --- STEP 1: ANALYSIS ---
            yield format_sse('thought', f"ğŸ¯ æ­£åœ¨è§£ææ•™å­¦éœ€æ±‚ï¼šã€{grade}ã€‘{topic}...")
            
            # --- STEP 2: RAG SEARCH ---
            # We keep grade in the text query for semantic reinforcement, 
            # but the heavy lifting is done by 'rag_filters'
            query = f"{grade} {topic}"
            yield format_sse('thought', f"ğŸ“š æ­£åœ¨æ£€ç´¢ç›¸å…³æ€æ”¿è¯¾æ ‡ä¸ç´ æ: '{query}' (Filter: {rag_filters})...")
            
            # Retrieve docs with Metadata Filtering
            # This ensures University content NEVER leaks into Primary School queries
            documents = rag_service.query(query, k=8, filters=rag_filters)
            
            if not documents:
                yield format_sse('thought', "âš ï¸ æœªæ‰¾åˆ°ç‰¹å®šç´ æï¼Œå°†åŸºäºé€šç”¨æ•™å­¦ç†è®ºè®¾è®¡ã€‚")
                context_text = ""
                sources = []
            else:
                sources = list(set([doc.metadata.get('source', 'Unknown') for doc in documents]))
                yield format_sse('thought', f"âœ… æ‰¾åˆ° {len(documents)} ä»½å‚è€ƒèµ„æ–™ï¼Œæ­£åœ¨æå–æ ¸å¿ƒè§‚ç‚¹...")
                yield format_sse('thought', f"ğŸ“„ å‚è€ƒæ¥æº: {', '.join(sources)}")
                
                # --- GROUP DOCUMENTS BY SOURCE ---
                grouped_docs = {}
                for doc in documents:
                    src = doc.metadata.get('source', 'Unknown')
                    if src not in grouped_docs:
                        grouped_docs[src] = []
                    grouped_docs[src].append(doc)
                
                context_text = ""
                for i, (source_name, docs) in enumerate(grouped_docs.items()):
                    doc_grade = docs[0].metadata.get('grade', 'é€šç”¨')
                    context_text += f"\nã€èµ„æ–™ {i+1}ã€‘ã€Š{source_name}ã€‹ (é€‚ç”¨: {doc_grade})\n"
                    for sub_doc in docs:
                        sub_page = sub_doc.metadata.get('page', '?')
                        context_text += f"   - [ç¬¬ {sub_page} é¡µ]: {sub_doc.page_content}\n"
                    context_text += "\n"

            # --- STEP 3: PROMPT CONSTRUCTION ---
            yield format_sse('thought', "ğŸ—ï¸ æ­£åœ¨æ„å»ºæ•™å­¦ç›®æ ‡ã€é‡éš¾ç‚¹ä¸äº’åŠ¨ç¯èŠ‚...")
            
            system_prompt = (
                "ä½ æ˜¯ä¸€åèµ„æ·±çš„å¤§ä¸­å°å­¦æ€æ”¿è¯¾éª¨å¹²æ•™å¸ˆã€‚è¯·æ ¹æ®èƒŒæ™¯èµ„æ–™è®¾è®¡æ•™æ¡ˆã€‚\n"
                "ä»»åŠ¡ï¼šè¯·åŸºäºæä¾›çš„èƒŒæ™¯èµ„æ–™ï¼Œä¸ºä¸€èŠ‚45åˆ†é’Ÿçš„æ€æ”¿è¯¾è®¾è®¡ä¸€ä»½è¯¦ç»†çš„æ•™æ¡ˆã€‚\n"
                "### ä¸¥ç¦é¡¹(Negative Constraints)\n"
                f"1. å¹´çº§ä¸¥æ ¼é™åˆ¶ï¼šå½“å‰ç›®æ ‡å¹´çº§ä¸ºã€{grade}ã€‘"
                "   - å¦‚æœæ˜¯å°å­¦ï¼š**ä¸¥ç¦**å‡ºç°åˆä¸­/é«˜ä¸­/å¤§å­¦/ç ”ç©¶ç”Ÿ/åšå£«çš„å¤æ‚çš„æ”¿æ²»æœ¯è¯­ã€å“²å­¦æ¦‚å¿µæˆ–è¿‡æ·±çš„ç†è®ºåˆ†æã€‚\n"
                "   - å¦‚æœæ˜¯å¤§å­¦ï¼š**ä¸¥ç¦**ä½¿ç”¨ä½å¹¼åŒ–çš„è¯­è¨€æˆ–ç®€å•çš„ç”Ÿæ´»æ¡ˆä¾‹ã€‚\n"
                "   - **ç»å¯¹ç¦æ­¢**å‘ç”Ÿâ€œå¹´çº§æ³„æ¼â€ã€‚\n"
                "2. **ä¸¥ç¦æé€ å¼•ç”¨**ï¼šæ•™æ¡ˆä¸­çš„å¼•ç”¨å¿…é¡»æ¥è‡ªèƒŒæ™¯èµ„æ–™ã€‚\n\n"
                "### ğŸ–Šï¸ è¾“å‡ºç»“æ„å¼ºåˆ¶è¦æ±‚ (å¿…é¡»å®Œå…¨éµå®ˆ):\n"
                "è¯·å°†ä½ çš„å›ç­”ä¸¥æ ¼åˆ’åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼š\n\n"
                "#### ç¬¬ä¸€éƒ¨åˆ†ï¼šğŸ“š çŸ¥è¯†åº“ç²¾å‡†ä¾æ® (Evidence Base)\n"
                "**å¿…é¡»æŒ‰æ¥æºä¹¦ç±åˆ†ç»„å±•ç¤º**ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n"
                "**ã€Šä¹¦ç±åç§° Aã€‹ã€1ã€‘**:\n"
                "1. \"...å¼•ç”¨åŸæ–‡ç‰‡æ®µ...\" (ç¬¬ 5 é¡µ)\n"
                "2. \"...å¼•ç”¨åŸæ–‡ç‰‡æ®µ...\" (ç¬¬ 12 é¡µ)\n\n"
                "#### ç¬¬äºŒéƒ¨åˆ†ï¼šğŸ“ æ•™æ¡ˆä¸»ä½“ (Lesson Plan)\n"
                "1. ç»“æ„å®Œæ•´ï¼ˆæ•™å­¦ç›®æ ‡ã€é‡éš¾ç‚¹ã€æ•™å­¦æ–¹æ³•ã€æ•™å­¦è¿‡ç¨‹ã€æ¿ä¹¦è®¾è®¡ï¼‰ã€‚\n"
                "2. åœ¨ã€æ•™å­¦è¿‡ç¨‹ã€‘ä¸­å¼•ç”¨èµ„æ–™æ—¶ï¼Œä½¿ç”¨ `ã€1ã€‘` æ ‡æ³¨æ¥æºã€‚\n"
                "3. **å¼•ç”¨ä½ç½®**ï¼šå¼•ç”¨ç¼–å·å¿…é¡»æ”¾åœ¨**å¥å·ä¹‹å** (e.g. ...æ•™å­¦å†…å®¹ã€‚ã€1ã€‘)ã€‚\n"
                
                f"### èƒŒæ™¯èµ„æ–™ (Indexed Context):\n{context_text}"
            )
            
            user_prompt = f"è¯·ä»¥ã€Š{topic}ã€‹ä¸ºä¸»é¢˜ï¼Œè®¾è®¡ä¸€ä»½é’ˆå¯¹ã€{grade}ã€‘å­¦ç”Ÿçš„æ•™æ¡ˆã€‚"

            # --- STEP 4: LLM STREAMING ---
            yield format_sse('thought', "âœï¸ å¼€å§‹æ’°å†™æ•™æ¡ˆ...")
            
            # Reusing the existing stream_response method from llm_service
            for token in llm_service.stream_response(user_prompt, system_prompt, history=[]):
                yield format_sse('token', token)
            
            # Construct Rich Citations
            rich_citations = []
            if documents:
                 for doc in documents:
                    meta = doc.metadata
                    rich_citations.append({
                        "source": meta.get('source', 'Unknown'),
                        "page": meta.get('page', '?'),
                        "grade": meta.get('grade', 'é€šç”¨'),
                        "content": doc.page_content[:300] + "..." # Snippet
                    })

            yield format_sse('done', {"sources": rich_citations})

        except Exception as e:
            traceback.print_exc()
            yield format_sse('error', str(e))

    return Response(stream_with_context(generate()), mimetype='text/event-stream')