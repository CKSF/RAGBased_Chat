import os
import sys
import shutil
import time
import importlib.util

def detect_grade(filename: str) -> str:
    """
    Auto-detects grade level from filename.
    Returns: 'Â∞èÂ≠¶', 'Âàù‰∏≠', 'È´ò‰∏≠', 'Â§ßÂ≠¶', "Á°ïÂ£´", "ÂçöÂ£´" or 'ÈÄöÁî®'
    """
    fname = filename.lower()
    if any(k in fname for k in ["Â∞èÂ≠¶", "‰∏ÄÂπ¥Á∫ß", "‰∫åÂπ¥Á∫ß", "‰∏âÂπ¥Á∫ß", "ÂõõÂπ¥Á∫ß", "‰∫îÂπ¥Á∫ß", "ÂÖ≠Âπ¥Á∫ß"]):
        return "Â∞èÂ≠¶"
    if any(k in fname for k in ["Âàù‰∏≠", "‰∏ÉÂπ¥Á∫ß", "ÂÖ´Âπ¥Á∫ß", "‰πùÂπ¥Á∫ß"]):
        return "Âàù‰∏≠"
    if any(k in fname for k in ["È´ò‰∏≠", "È´ò‰∏Ä", "È´ò‰∫å", "È´ò‰∏â"]):
        return "È´ò‰∏≠"
    if any(k in fname for k in ["Â§ßÂ≠¶", "Êú¨Áßë"]):
        return "Â§ßÂ≠¶"
    if any(k in fname for k in ["Á†îÁ©∂Áîü", "Á°ïÂ£´"]):
        return "Á°ïÂ£´"
    if any(k in fname for k in ["ÂçöÂ£´", "ÂçöÂ£´Âêé"]):
        return "ÂçöÂ£´"
    
    return "ÈÄöÁî®"  # Default fallback

def build_knowledge_base():
    print("\n" + "="*50)
    print("üöÄ STARTING DATABASE BUILD (With Page-Level Metadata)")
    print("="*50)

    # 1. CLEANUP
    print("üßπ [Step 1] Cleaning up old database...")
    if os.path.exists("chroma_db"):
        try:
            shutil.rmtree("chroma_db")
            print("   -> Removed chroma_db")
        except OSError as e:
            print(f"   ‚ö†Ô∏è Could not delete chroma_db: {e}")
            
    if os.path.exists("doc_store"):
        shutil.rmtree("doc_store", ignore_errors=True)
        print("   -> Removed doc_store")

    # 2. INIT
    print("\nüöÄ [Step 2] Initializing RAG Service...")
    try:
        # Load PDFService manually
        pdf_spec = importlib.util.spec_from_file_location("pdf_service", "backend/app/services/pdf_service.py")
        pdf_module = importlib.util.module_from_spec(pdf_spec)
        pdf_spec.loader.exec_module(pdf_module)
        PDFService = pdf_module.PDFService
        
        # Load DocxService
        docx_spec = importlib.util.spec_from_file_location("docx_service", "backend/app/services/docx_service.py")
        docx_module = importlib.util.module_from_spec(docx_spec)
        docx_spec.loader.exec_module(docx_module)
        DocxService = docx_module.DocxService

        # Load RAGService manually
        rag_spec = importlib.util.spec_from_file_location("rag_service", "backend/app/services/rag_service.py")
        rag_module = importlib.util.module_from_spec(rag_spec)
        rag_spec.loader.exec_module(rag_module)
        RAGService = rag_module.RAGService
        
        rag = RAGService(persist_directory="chroma_db", parent_store_directory="doc_store")
        
    except Exception as e:
        print(f"‚ùå CRITICAL ERROR initializing RAG: {e}")
        import traceback
        traceback.print_exc()
        return

    # 3. SCAN & INDEX
    data_dir = "data"
    if not os.path.exists(data_dir):
        print(f"‚ùå Error: Data directory '{data_dir}' not found.")
        return

    files = [f for f in os.listdir(data_dir) if f.lower().endswith((".pdf", ".docx"))]
    print(f"\nüìÇ [Step 3] Scanning '{data_dir}': Found {len(files)} files.")
    
    success_count = 0
    
    for i, filename in enumerate(files):
        print(f"\n--- Processing File {i+1}/{len(files)}: {filename} ---")
        file_path = os.path.join(data_dir, filename)
        absolute_path = os.path.abspath(file_path)
        
        # [CRITICAL] Detect Grade
        grade_tag = detect_grade(filename)
        print(f"   üè∑Ô∏è  Detected Grade: [{grade_tag}]")
        
        try:
            print("   [1/3] Extracting text with metadata...", end=" ", flush=True)
            documents = [] # List[Dict]
            
            if filename.lower().endswith(".pdf"):
                documents = PDFService.extract_text(absolute_path)
            elif filename.lower().endswith(".docx"):
                documents = DocxService.extract_text(absolute_path)
            
            print(f"Done. Found {len(documents)} pages/chunks.")

            if not documents:
                print("   ‚ö†Ô∏è [WARN] Extracted content is empty. Skipping.")
                continue
            
            print(f"   [2/3] Sending to ChromaDB...")
            
            total_pages = len(documents)
            previous_tail = ""  # Buffer for cross-page context
            OVERLAP_SIZE = 300  # Characters to carry over
            
            for p_idx, doc_item in enumerate(documents):
                raw_text = doc_item['page_content']
                page_meta = doc_item['metadata'] # {"page": x}
                
                # [CRITICAL] Context Continuity
                # Prepend the tail of the previous page to the current page.
                # This ensures that sentences split across pages are not lost in retrieval.
                text_with_context = previous_tail + "\n" + raw_text if previous_tail else raw_text
                
                # Combine Global Metadata (Source, Grade) with Local Metadata (Page)
                combined_meta = {
                    "source": filename,
                    "grade": grade_tag,
                    **page_meta
                }
                
                rag.add_documents(text_with_context, metadata=combined_meta)
                
                # Update buffer for next iteration
                # Take the last N characters of *original* raw_text (not the combined one)
                if len(raw_text) > OVERLAP_SIZE:
                    previous_tail = raw_text[-OVERLAP_SIZE:]
                else:
                    previous_tail = raw_text # Keep whole text if small
                
                # Progress bar
                if p_idx % 5 == 0:
                    print(f"\r        Processed Page {p_idx+1}/{total_pages} ...", end="", flush=True)
            
            print(f"\r        Processed Page {total_pages}/{total_pages} ... Done.")
            print("        ‚úÖ File Completed.")
            success_count += 1
            
        except Exception as e:
            print(f"\n   ‚ùå [ERROR] Failed processing {filename}")
            print(f"   Error details: {e}")
            import traceback
            traceback.print_exc()

    # 4. FINAL VERIFICATION
    print("\n" + "="*50)
    print(f"üéâ Build Finished! Successfully processed {success_count}/{len(files)} files.")
    
    if os.path.exists("chroma_db/chroma.sqlite3"):
        print("   ‚úÖ chroma.sqlite3 found.")
    else:
        print("   ‚ùå chroma.sqlite3 NOT found. Persistence failed.")
    print("="*50)

if __name__ == "__main__":
    build_knowledge_base()